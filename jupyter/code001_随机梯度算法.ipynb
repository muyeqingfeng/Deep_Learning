{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sample_num=1000\n",
    "x1 = np.linspace(1, 100, sample_num)\n",
    "x2 = np.linspace(1, 5, sample_num)\n",
    "x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "y = np.dot(x, np.array([3, 6]).T)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(samples, y, step_size=2, max_iter_count=1000):\n",
    "    \"\"\"\n",
    "    :param samples: 样本\n",
    "    :param y: 结果value\n",
    "    :param step_size: 每一接迭代的步长\n",
    "    :param max_iter_count: 最大的迭代次数\n",
    "    :param batch_size: 随机选取的相对于总样本的大小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #确定样本数量以及变量的个数初始化theta值\n",
    "    \n",
    "    m, var = samples.shape\n",
    "    theta = np.zeros(2)\n",
    "    y = y.flatten()\n",
    "    #进入循环内\n",
    "    loss = 1\n",
    "    iter_count = 0\n",
    "    iter_list=[]\n",
    "    loss_list=[]\n",
    "    theta1=[]\n",
    "    theta2=[]\n",
    "    #当损失精度大于0.01且迭代此时小于最大迭代次数时，进行\n",
    "    while loss > 0.01 and iter_count < max_iter_count:\n",
    "        loss = 0\n",
    "        #梯度计算\n",
    "        theta1.append(theta[0])\n",
    "        theta2.append(theta[1])      \n",
    "        #样本维数下标\n",
    "        rand1 = np.random.randint(0,m,1)\n",
    "        h = np.dot(theta,samples[rand1].T)\n",
    "        #关键点，只需要一个样本点来更新权值\n",
    "        for i in range(len(theta)):\n",
    "            theta[i] =theta[i] - step_size*(1/m)*(h - y[rand1])*samples[rand1,i]\n",
    "        #计算总体的损失精度，等于各个样本损失精度之和\n",
    "        for i in range(m):\n",
    "            h = np.dot(theta.T, samples[i])\n",
    "            #每组样本点损失的精度\n",
    "            every_loss = (1/(var*m))*np.power((h - y[i]), 2)\n",
    "            loss = loss + every_loss\n",
    " \n",
    "        print(\"iter_count: \", iter_count, \"the loss:\", loss)\n",
    "        \n",
    "        iter_list.append(iter_count)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        iter_count += 1\n",
    "    plt.plot(iter_list,loss_list)\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "    return theta1,theta2,theta,loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  0 the loss: 661759.68936693\n",
      "iter_count:  1 the loss: 98972.11364439059\n",
      "iter_count:  2 the loss: 12326523.756372593\n",
      "iter_count:  3 the loss: 407068473.91173184\n",
      "iter_count:  4 the loss: 1629761357.7022617\n",
      "iter_count:  5 the loss: 22972269624.536457\n",
      "iter_count:  6 the loss: 5861013750.882404\n",
      "iter_count:  7 the loss: 224651254097.03857\n",
      "iter_count:  8 the loss: 220166151627.64017\n",
      "iter_count:  9 the loss: 16113180674.29719\n",
      "iter_count:  10 the loss: 182166871.30617377\n",
      "iter_count:  11 the loss: 236152880.765696\n",
      "iter_count:  12 the loss: 191011417.40836865\n",
      "iter_count:  13 the loss: 299557745.28146315\n",
      "iter_count:  14 the loss: 2123390421.9566665\n",
      "iter_count:  15 the loss: 668507438.6707017\n",
      "iter_count:  16 the loss: 117616435006.32915\n",
      "iter_count:  17 the loss: 751567344248.3597\n",
      "iter_count:  18 the loss: 422611102185.24976\n",
      "iter_count:  19 the loss: 918605186596.2197\n",
      "iter_count:  20 the loss: 246027019769920.1\n",
      "iter_count:  21 the loss: 1111247050250998.5\n",
      "iter_count:  22 the loss: 1.9881004047629476e+16\n",
      "iter_count:  23 the loss: 3.012801147940551e+18\n",
      "iter_count:  24 the loss: 4.5483993495685647e+18\n",
      "iter_count:  25 the loss: 6.50542041549046e+17\n",
      "iter_count:  26 the loss: 2.197578586664195e+20\n",
      "iter_count:  27 the loss: 1.1200785820430211e+20\n",
      "iter_count:  28 the loss: 1.5812504595644387e+20\n",
      "iter_count:  29 the loss: 2.69676649307086e+21\n",
      "iter_count:  30 the loss: 7.302981678053329e+22\n",
      "iter_count:  31 the loss: 8.607738366166701e+22\n",
      "iter_count:  32 the loss: 1.732810848321347e+23\n",
      "iter_count:  33 the loss: 3.856513736087802e+25\n",
      "iter_count:  34 the loss: 1.2354085044365267e+26\n",
      "iter_count:  35 the loss: 3.4380190206656723e+25\n",
      "iter_count:  36 the loss: 3.0279494948195144e+27\n",
      "iter_count:  37 the loss: 2.917409096191327e+27\n",
      "iter_count:  38 the loss: 4.4446465450184785e+29\n",
      "iter_count:  39 the loss: 8.902868264517593e+30\n",
      "iter_count:  40 the loss: 2.4940350321278876e+32\n",
      "iter_count:  41 the loss: 1.3386088392101503e+34\n",
      "iter_count:  42 the loss: 8.407670717087484e+35\n",
      "iter_count:  43 the loss: 1.657946920167517e+36\n",
      "iter_count:  44 the loss: 3.2126933846716473e+35\n",
      "iter_count:  45 the loss: 6.141549290843988e+36\n",
      "iter_count:  46 the loss: 1.2659470278305453e+39\n",
      "iter_count:  47 the loss: 1.043311909805093e+40\n",
      "iter_count:  48 the loss: 1.1175091317875917e+40\n",
      "iter_count:  49 the loss: 1.0580866095736794e+42\n",
      "iter_count:  50 the loss: 2.036936796902945e+44\n",
      "iter_count:  51 the loss: 7.469889997990827e+43\n",
      "iter_count:  52 the loss: 2.266623121983491e+46\n",
      "iter_count:  53 the loss: 6.243228797875899e+47\n",
      "iter_count:  54 the loss: 6.803647630651107e+48\n",
      "iter_count:  55 the loss: 1.3422671565570189e+51\n",
      "iter_count:  56 the loss: 3.8203748988884625e+51\n",
      "iter_count:  57 the loss: 2.631856494424249e+53\n",
      "iter_count:  58 the loss: 9.197383651446705e+55\n",
      "iter_count:  59 the loss: 2.07312906166552e+56\n",
      "iter_count:  60 the loss: 1.647961581358181e+57\n",
      "iter_count:  61 the loss: 1.2350799146130808e+57\n",
      "iter_count:  62 the loss: 3.4142470521012877e+59\n",
      "iter_count:  63 the loss: 6.712785833825275e+60\n",
      "iter_count:  64 the loss: 2.200916988604147e+63\n",
      "iter_count:  65 the loss: 7.742346815931796e+64\n",
      "iter_count:  66 the loss: 7.701169850153277e+64\n",
      "iter_count:  67 the loss: 1.198026730113745e+67\n",
      "iter_count:  68 the loss: 4.8808803205077465e+66\n",
      "iter_count:  69 the loss: 7.634297333021388e+68\n",
      "iter_count:  70 the loss: 3.37549389954428e+70\n",
      "iter_count:  71 the loss: 7.564452064026835e+69\n",
      "iter_count:  72 the loss: 7.184444432472691e+70\n",
      "iter_count:  73 the loss: 1.3356940640799742e+73\n",
      "iter_count:  74 the loss: 3.4186984988802276e+75\n",
      "iter_count:  75 the loss: 2.448600284102094e+77\n",
      "iter_count:  76 the loss: 2.062889365353747e+77\n",
      "iter_count:  77 the loss: 2.653051098425512e+76\n",
      "iter_count:  78 the loss: 1.4844260900800752e+78\n",
      "iter_count:  79 the loss: 1.0716927355032031e+78\n",
      "iter_count:  80 the loss: 1.5577824072233893e+76\n",
      "iter_count:  81 the loss: 5.648827778676254e+78\n",
      "iter_count:  82 the loss: 8.926488518961457e+80\n",
      "iter_count:  83 the loss: 3.4207083436616126e+82\n",
      "iter_count:  84 the loss: 9.412543634432441e+84\n",
      "iter_count:  85 the loss: 7.562034356015006e+84\n",
      "iter_count:  86 the loss: 2.8445262533542478e+85\n",
      "iter_count:  87 the loss: 4.5693151814442837e+83\n",
      "iter_count:  88 the loss: 2.301640932398753e+85\n",
      "iter_count:  89 the loss: 4.836983961585502e+87\n",
      "iter_count:  90 the loss: 6.07322950889504e+88\n",
      "iter_count:  91 the loss: 3.0810776747948535e+89\n",
      "iter_count:  92 the loss: 1.4927578071950596e+89\n",
      "iter_count:  93 the loss: 5.210825949305933e+90\n",
      "iter_count:  94 the loss: 1.553138990658505e+93\n",
      "iter_count:  95 the loss: 9.957901341464513e+89\n",
      "iter_count:  96 the loss: 1.5523341741720088e+92\n",
      "iter_count:  97 the loss: 3.827165095793252e+93\n",
      "iter_count:  98 the loss: 6.5854689245289695e+94\n",
      "iter_count:  99 the loss: 4.1069990667504205e+94\n",
      "iter_count:  100 the loss: 3.4282300654135695e+95\n",
      "iter_count:  101 the loss: 2.364336677971846e+94\n",
      "iter_count:  102 the loss: 7.368258541031674e+96\n",
      "iter_count:  103 the loss: 2.5857024486389197e+99\n",
      "iter_count:  104 the loss: 1.1237970408802391e+98\n",
      "iter_count:  105 the loss: 1.1836523762052921e+100\n",
      "iter_count:  106 the loss: 5.3632567608118975e+99\n",
      "iter_count:  107 the loss: 1.3800786312853638e+101\n",
      "iter_count:  108 the loss: 3.7131437616245906e+103\n",
      "iter_count:  109 the loss: 2.076714295093437e+104\n",
      "iter_count:  110 the loss: 8.842334865834652e+104\n",
      "iter_count:  111 the loss: 1.5901203767158951e+102\n",
      "iter_count:  112 the loss: 1.901528077964156e+104\n",
      "iter_count:  113 the loss: 2.2060151270610418e+106\n",
      "iter_count:  114 the loss: 5.935565071640058e+108\n",
      "iter_count:  115 the loss: 1.1027724625201737e+109\n",
      "iter_count:  116 the loss: 1.3705174534362964e+110\n",
      "iter_count:  117 the loss: 5.415203146324654e+111\n",
      "iter_count:  118 the loss: 2.0950964727236763e+111\n",
      "iter_count:  119 the loss: 2.1303273089112686e+111\n",
      "iter_count:  120 the loss: 1.934617863384438e+112\n",
      "iter_count:  121 the loss: 3.18630332316398e+114\n",
      "iter_count:  122 the loss: 5.020765832916244e+114\n",
      "iter_count:  123 the loss: 1.1711485775937639e+117\n",
      "iter_count:  124 the loss: 2.114918447440385e+118\n",
      "iter_count:  125 the loss: 5.217266987568185e+120\n",
      "iter_count:  126 the loss: 1.8697781420376125e+123\n",
      "iter_count:  127 the loss: 9.15328172108543e+124\n",
      "iter_count:  128 the loss: 7.628631964993987e+126\n",
      "iter_count:  129 the loss: 4.144548661917411e+126\n",
      "iter_count:  130 the loss: 5.201165522953309e+128\n",
      "iter_count:  131 the loss: 3.53060709940386e+128\n",
      "iter_count:  132 the loss: 8.99633519010025e+130\n",
      "iter_count:  133 the loss: 8.71415775536174e+130\n",
      "iter_count:  134 the loss: 3.365547316460964e+132\n",
      "iter_count:  135 the loss: 3.71023470134174e+134\n",
      "iter_count:  136 the loss: 3.597810543821002e+136\n",
      "iter_count:  137 the loss: 9.74377271260112e+132\n",
      "iter_count:  138 the loss: 4.85757476962947e+134\n",
      "iter_count:  139 the loss: 6.760993078409522e+133\n",
      "iter_count:  140 the loss: 4.313692094207541e+133\n",
      "iter_count:  141 the loss: 6.012440013989386e+135\n",
      "iter_count:  142 the loss: 4.82940916479274e+136\n",
      "iter_count:  143 the loss: 2.1197945691813977e+138\n",
      "iter_count:  144 the loss: 4.882513725007904e+137\n",
      "iter_count:  145 the loss: 6.595512860229051e+138\n",
      "iter_count:  146 the loss: 2.8735650540878152e+140\n",
      "iter_count:  147 the loss: 2.0881304750537574e+140\n",
      "iter_count:  148 the loss: 2.0466406580210033e+140\n",
      "iter_count:  149 the loss: 2.7111901279885955e+137\n",
      "iter_count:  150 the loss: 5.882911765359928e+139\n",
      "iter_count:  151 the loss: 1.2717269156834165e+140\n",
      "iter_count:  152 the loss: 5.299458792596267e+141\n",
      "iter_count:  153 the loss: 1.3257259231899874e+144\n",
      "iter_count:  154 the loss: 1.2284177965591757e+144\n",
      "iter_count:  155 the loss: 4.458839000425137e+145\n",
      "iter_count:  156 the loss: 1.0598948515984889e+148\n",
      "iter_count:  157 the loss: 8.214898581755625e+148\n",
      "iter_count:  158 the loss: 1.6206316711556878e+151\n",
      "iter_count:  159 the loss: 7.929728756015019e+150\n",
      "iter_count:  160 the loss: 7.351283717430496e+150\n",
      "iter_count:  161 the loss: 4.295363652766961e+150\n",
      "iter_count:  162 the loss: 3.1341330916212466e+151\n",
      "iter_count:  163 the loss: 4.200660188138597e+153\n",
      "iter_count:  164 the loss: 4.7846572652201635e+154\n",
      "iter_count:  165 the loss: 3.276166467765828e+154\n",
      "iter_count:  166 the loss: 3.695240822631017e+156\n",
      "iter_count:  167 the loss: 2.199154606649548e+158\n",
      "iter_count:  168 the loss: 1.844209702071951e+160\n",
      "iter_count:  169 the loss: 2.566822086694684e+162\n",
      "iter_count:  170 the loss: 4.680490622740244e+159\n",
      "iter_count:  171 the loss: 1.087925363887482e+162\n",
      "iter_count:  172 the loss: 1.4029767204622069e+164\n",
      "iter_count:  173 the loss: 1.618767342501706e+166\n",
      "iter_count:  174 the loss: 1.8368826077695885e+165\n",
      "iter_count:  175 the loss: 8.547554484781938e+166\n",
      "iter_count:  176 the loss: 3.0787170849909002e+168\n",
      "iter_count:  177 the loss: 1.591246690702197e+168\n",
      "iter_count:  178 the loss: 6.987267947421326e+168\n",
      "iter_count:  179 the loss: 9.397889118298118e+167\n",
      "iter_count:  180 the loss: 6.687197045496937e+169\n",
      "iter_count:  181 the loss: 5.6664726889104705e+169\n",
      "iter_count:  182 the loss: 1.85349395209393e+169\n",
      "iter_count:  183 the loss: 6.5097324780906826e+171\n",
      "iter_count:  184 the loss: 7.093568273257837e+172\n",
      "iter_count:  185 the loss: 1.4550896540994944e+175\n",
      "iter_count:  186 the loss: 7.020631699952023e+174\n",
      "iter_count:  187 the loss: 6.138079764122757e+174\n",
      "iter_count:  188 the loss: 2.3337369695158811e+176\n",
      "iter_count:  189 the loss: 9.341378581082936e+175\n",
      "iter_count:  190 the loss: 7.459521302468667e+175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  191 the loss: 7.255434347088772e+175\n",
      "iter_count:  192 the loss: 4.201739758072351e+177\n",
      "iter_count:  193 the loss: 5.3897954537339665e+178\n",
      "iter_count:  194 the loss: 2.231340753933052e+178\n",
      "iter_count:  195 the loss: 2.891535649188108e+179\n",
      "iter_count:  196 the loss: 4.647166444579025e+180\n",
      "iter_count:  197 the loss: 1.5804860924854564e+179\n",
      "iter_count:  198 the loss: 1.081819000071606e+181\n",
      "iter_count:  199 the loss: 5.9198229264830424e+178\n",
      "iter_count:  200 the loss: 3.266602056300174e+178\n",
      "iter_count:  201 the loss: 2.3751590742504393e+178\n",
      "iter_count:  202 the loss: 6.947570072362343e+179\n",
      "iter_count:  203 the loss: 1.4700870059508202e+181\n",
      "iter_count:  204 the loss: 1.7153397256716567e+183\n",
      "iter_count:  205 the loss: 5.969308395127021e+185\n",
      "iter_count:  206 the loss: 1.4118287891482275e+185\n",
      "iter_count:  207 the loss: 3.710590156209978e+184\n",
      "iter_count:  208 the loss: 1.688926922632661e+186\n",
      "iter_count:  209 the loss: 5.631904385860223e+188\n",
      "iter_count:  210 the loss: 4.607369645636144e+190\n",
      "iter_count:  211 the loss: 8.643350055489372e+191\n",
      "iter_count:  212 the loss: 2.8624607498631194e+192\n",
      "iter_count:  213 the loss: 2.5674532451890145e+194\n",
      "iter_count:  214 the loss: 6.118075016433292e+194\n",
      "iter_count:  215 the loss: 6.08775499753639e+194\n",
      "iter_count:  216 the loss: 5.942937522774466e+194\n",
      "iter_count:  217 the loss: 1.6508864530615513e+196\n",
      "iter_count:  218 the loss: 4.5260686088275847e+195\n",
      "iter_count:  219 the loss: 2.4938698637827893e+195\n",
      "iter_count:  220 the loss: 2.9252839364855296e+195\n",
      "iter_count:  221 the loss: 9.89605881755728e+196\n",
      "iter_count:  222 the loss: 3.0846602084074235e+195\n",
      "iter_count:  223 the loss: 1.527408486627127e+195\n",
      "iter_count:  224 the loss: 1.962181049389574e+197\n",
      "iter_count:  225 the loss: 4.3075009823657197e+194\n",
      "iter_count:  226 the loss: 6.911370559970246e+193\n",
      "iter_count:  227 the loss: 2.373089810437717e+195\n",
      "iter_count:  228 the loss: 6.5375355346029995e+196\n",
      "iter_count:  229 the loss: 9.042917950408987e+196\n",
      "iter_count:  230 the loss: 7.10085848468808e+197\n",
      "iter_count:  231 the loss: 5.555577206225212e+197\n",
      "iter_count:  232 the loss: 1.2526630874847879e+199\n",
      "iter_count:  233 the loss: 3.971984695054234e+200\n",
      "iter_count:  234 the loss: 1.0783205654515261e+203\n",
      "iter_count:  235 the loss: 2.1067818056041017e+205\n",
      "iter_count:  236 the loss: 3.701780367954365e+204\n",
      "iter_count:  237 the loss: 1.124195253171059e+203\n",
      "iter_count:  238 the loss: 1.025634164794999e+204\n",
      "iter_count:  239 the loss: 3.467980669055673e+206\n",
      "iter_count:  240 the loss: 3.189852799595905e+206\n",
      "iter_count:  241 the loss: 3.166749533101655e+206\n",
      "iter_count:  242 the loss: 1.6877986611500257e+208\n",
      "iter_count:  243 the loss: 8.932867811123761e+209\n",
      "iter_count:  244 the loss: 8.64731103931401e+209\n",
      "iter_count:  245 the loss: 3.464592270505939e+209\n",
      "iter_count:  246 the loss: 3.886037480464182e+211\n",
      "iter_count:  247 the loss: 2.3582683000382756e+212\n",
      "iter_count:  248 the loss: 2.4298086353177512e+213\n",
      "iter_count:  249 the loss: 9.583938018850562e+213\n",
      "iter_count:  250 the loss: 4.5543629182814077e+213\n",
      "iter_count:  251 the loss: 1.4577031027931095e+213\n",
      "iter_count:  252 the loss: 6.672038650117544e+213\n",
      "iter_count:  253 the loss: 1.1328013059899864e+216\n",
      "iter_count:  254 the loss: 7.404670327147493e+217\n",
      "iter_count:  255 the loss: 6.993416142789989e+217\n",
      "iter_count:  256 the loss: 6.66481853664923e+217\n",
      "iter_count:  257 the loss: 2.471558370484018e+218\n",
      "iter_count:  258 the loss: 3.6672583359750434e+220\n",
      "iter_count:  259 the loss: 1.0930629974526405e+223\n",
      "iter_count:  260 the loss: 4.061332047106505e+224\n",
      "iter_count:  261 the loss: 1.5407992213217949e+224\n",
      "iter_count:  262 the loss: 2.5516270128493703e+225\n",
      "iter_count:  263 the loss: 7.021628873427715e+227\n",
      "iter_count:  264 the loss: 1.7351894734865755e+228\n",
      "iter_count:  265 the loss: 1.3164166598825219e+230\n",
      "iter_count:  266 the loss: 7.024218968613822e+229\n",
      "iter_count:  267 the loss: 2.0201111381227232e+232\n",
      "iter_count:  268 the loss: 4.008778264565736e+233\n",
      "iter_count:  269 the loss: 5.797612441910469e+233\n",
      "iter_count:  270 the loss: 5.7262216975707905e+233\n",
      "iter_count:  271 the loss: 1.043816415945323e+234\n",
      "iter_count:  272 the loss: 3.1288297672670883e+234\n",
      "iter_count:  273 the loss: 2.217377583220217e+234\n",
      "iter_count:  274 the loss: 1.8366446076725643e+236\n",
      "iter_count:  275 the loss: 6.125976733952726e+238\n",
      "iter_count:  276 the loss: 1.5617837086318848e+238\n",
      "iter_count:  277 the loss: 4.314161918464246e+240\n",
      "iter_count:  278 the loss: 4.621244213000873e+242\n",
      "iter_count:  279 the loss: 5.09448030706731e+244\n",
      "iter_count:  280 the loss: 1.0563098868232751e+243\n",
      "iter_count:  281 the loss: 3.249706149749312e+243\n",
      "iter_count:  282 the loss: 1.0395092480505564e+245\n",
      "iter_count:  283 the loss: 3.2424335724703873e+246\n",
      "iter_count:  284 the loss: 1.0963966013950784e+248\n",
      "iter_count:  285 the loss: 1.0319640695886008e+250\n",
      "iter_count:  286 the loss: 9.144325021061269e+249\n",
      "iter_count:  287 the loss: 2.4973527438479073e+251\n",
      "iter_count:  288 the loss: 2.7827395343378474e+252\n",
      "iter_count:  289 the loss: 2.7705222865016164e+253\n",
      "iter_count:  290 the loss: 1.2703551815443016e+254\n",
      "iter_count:  291 the loss: 2.250898921700763e+255\n",
      "iter_count:  292 the loss: 2.5387103649018357e+257\n",
      "iter_count:  293 the loss: 1.513916389920238e+257\n",
      "iter_count:  294 the loss: 7.410922997951797e+258\n",
      "iter_count:  295 the loss: 5.595205970247787e+258\n",
      "iter_count:  296 the loss: 4.021695078083401e+259\n",
      "iter_count:  297 the loss: 3.0038684609291306e+260\n",
      "iter_count:  298 the loss: 2.782998334123228e+260\n",
      "iter_count:  299 the loss: 8.19623862489811e+261\n",
      "iter_count:  300 the loss: 4.2473650292576374e+263\n",
      "iter_count:  301 the loss: 3.242895649075602e+265\n",
      "iter_count:  302 the loss: 2.9846390473409166e+265\n",
      "iter_count:  303 the loss: 9.775781336392394e+266\n",
      "iter_count:  304 the loss: 5.977405362231289e+268\n",
      "iter_count:  305 the loss: 7.336801088277595e+266\n",
      "iter_count:  306 the loss: 2.6373281089611294e+266\n",
      "iter_count:  307 the loss: 5.766341806572952e+267\n",
      "iter_count:  308 the loss: 1.0450950349714498e+270\n",
      "iter_count:  309 the loss: 5.570097179855908e+271\n",
      "iter_count:  310 the loss: 5.516695188026128e+271\n",
      "iter_count:  311 the loss: 7.614759660375072e+272\n",
      "iter_count:  312 the loss: 7.531907192659849e+272\n",
      "iter_count:  313 the loss: 6.009787716410014e+274\n",
      "iter_count:  314 the loss: 5.963531949828262e+273\n",
      "iter_count:  315 the loss: 1.4996356839199855e+276\n",
      "iter_count:  316 the loss: 4.4903308695179015e+277\n",
      "iter_count:  317 the loss: 6.627512541244759e+279\n",
      "iter_count:  318 the loss: 2.378766930085182e+280\n",
      "iter_count:  319 the loss: 3.20492197542987e+282\n",
      "iter_count:  320 the loss: 8.240460890881645e+284\n",
      "iter_count:  321 the loss: 6.172925689710605e+286\n",
      "iter_count:  322 the loss: 1.1690196285969758e+288\n",
      "iter_count:  323 the loss: 4.175590520583436e+285\n",
      "iter_count:  324 the loss: 9.714830316638122e+284\n",
      "iter_count:  325 the loss: 4.991008236258237e+284\n",
      "iter_count:  326 the loss: 4.212302053237604e+283\n",
      "iter_count:  327 the loss: 1.1128240822112686e+286\n",
      "iter_count:  328 the loss: 1.1046236048151157e+286\n",
      "iter_count:  329 the loss: 2.1554065683398952e+285\n",
      "iter_count:  330 the loss: 2.468069182995087e+287\n",
      "iter_count:  331 the loss: 3.511680908140473e+288\n",
      "iter_count:  332 the loss: 8.20765572129879e+289\n",
      "iter_count:  333 the loss: 2.3185916208731317e+291\n",
      "iter_count:  334 the loss: 1.1105461242359602e+292\n",
      "iter_count:  335 the loss: 1.6141012696336887e+293\n",
      "iter_count:  336 the loss: 5.711948757702534e+295\n",
      "iter_count:  337 the loss: 9.950348849719488e+297\n",
      "iter_count:  338 the loss: 9.033907929005416e+299\n",
      "iter_count:  339 the loss: 3.9943190727056973e+301\n",
      "iter_count:  340 the loss: 4.401399372809009e+302\n",
      "iter_count:  341 the loss: 1.1422003596883354e+304\n",
      "iter_count:  342 the loss: 2.4119715933627698e+306\n",
      "iter_count:  343 the loss: inf\n",
      "iter_count: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-b3333ed59782>:38: RuntimeWarning: overflow encountered in power\n",
      "  every_loss = (1/(var*m))*np.power((h - y[i]), 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 344 the loss: inf\n",
      "iter_count:  345 the loss: inf\n",
      "iter_count:  346 the loss: inf\n",
      "iter_count:  347 the loss: inf\n",
      "iter_count:  348 the loss: inf\n",
      "iter_count:  349 the loss: inf\n",
      "iter_count:  350 the loss: inf\n",
      "iter_count:  351 the loss: inf\n",
      "iter_count:  352 the loss: inf\n",
      "iter_count:  353 the loss: inf\n",
      "iter_count:  354 the loss: inf\n",
      "iter_count:  355 the loss: inf\n",
      "iter_count:  356 the loss: inf\n",
      "iter_count:  357 the loss: inf\n",
      "iter_count:  358 the loss: inf\n",
      "iter_count:  359 the loss: inf\n",
      "iter_count:  360 the loss: inf\n",
      "iter_count:  361 the loss: inf\n",
      "iter_count:  362 the loss: inf\n",
      "iter_count:  363 the loss: inf\n",
      "iter_count:  364 the loss: inf\n",
      "iter_count:  365 the loss: inf\n",
      "iter_count:  366 the loss: inf\n",
      "iter_count:  367 the loss: inf\n",
      "iter_count:  368 the loss: inf\n",
      "iter_count:  369 the loss: inf\n",
      "iter_count:  370 the loss: inf\n",
      "iter_count:  371 the loss: inf\n",
      "iter_count:  372 the loss: inf\n",
      "iter_count:  373 the loss: inf\n",
      "iter_count:  374 the loss: inf\n",
      "iter_count:  375 the loss: inf\n",
      "iter_count:  376 the loss: inf\n",
      "iter_count:  377 the loss: inf\n",
      "iter_count:  378 the loss: inf\n",
      "iter_count:  379 the loss: inf\n",
      "iter_count:  380 the loss: inf\n",
      "iter_count:  381 the loss: inf\n",
      "iter_count:  382 the loss: inf\n",
      "iter_count:  383 the loss: inf\n",
      "iter_count:  384 the loss: inf\n",
      "iter_count:  385 the loss: inf\n",
      "iter_count:  386 the loss: inf\n",
      "iter_count:  387 the loss: inf\n",
      "iter_count:  388 the loss: inf\n",
      "iter_count:  389 the loss: inf\n",
      "iter_count:  390 the loss: inf\n",
      "iter_count:  391 the loss: inf\n",
      "iter_count:  392 the loss: inf\n",
      "iter_count:  393 the loss: inf\n",
      "iter_count:  394 the loss: inf\n",
      "iter_count:  395 the loss: inf\n",
      "iter_count:  396 the loss: inf\n",
      "iter_count:  397 the loss: inf\n",
      "iter_count:  398 the loss: inf\n",
      "iter_count:  399 the loss: inf\n",
      "iter_count:  400 the loss: inf\n",
      "iter_count:  401 the loss: inf\n",
      "iter_count:  402 the loss: inf\n",
      "iter_count:  403 the loss: inf\n",
      "iter_count:  404 the loss: inf\n",
      "iter_count:  405 the loss: inf\n",
      "iter_count:  406 the loss: inf\n",
      "iter_count:  407 the loss: inf\n",
      "iter_count:  408 the loss: inf\n",
      "iter_count:  409 the loss: inf\n",
      "iter_count:  410 the loss: inf\n",
      "iter_count:  411 the loss: inf\n",
      "iter_count:  412 the loss: inf\n",
      "iter_count:  413 the loss: inf\n",
      "iter_count:  414 the loss: inf\n",
      "iter_count:  415 the loss: inf\n",
      "iter_count:  416 the loss: inf\n",
      "iter_count:  417 the loss: inf\n",
      "iter_count:  418 the loss: inf\n",
      "iter_count:  419 the loss: inf\n",
      "iter_count:  420 the loss: inf\n",
      "iter_count:  421 the loss: inf\n",
      "iter_count:  422 the loss: inf\n",
      "iter_count:  423 the loss: inf\n",
      "iter_count:  424 the loss: inf\n",
      "iter_count:  425 the loss: inf\n",
      "iter_count:  426 the loss: inf\n",
      "iter_count:  427 the loss: inf\n",
      "iter_count:  428 the loss: inf\n",
      "iter_count:  429 the loss: inf\n",
      "iter_count:  430 the loss: inf\n",
      "iter_count:  431 the loss: inf\n",
      "iter_count:  432 the loss: inf\n",
      "iter_count:  433 the loss: inf\n",
      "iter_count:  434 the loss: inf\n",
      "iter_count:  435 the loss: inf\n",
      "iter_count:  436 the loss: inf\n",
      "iter_count:  437 the loss: inf\n",
      "iter_count:  438 the loss: inf\n",
      "iter_count:  439 the loss: inf\n",
      "iter_count:  440 the loss: inf\n",
      "iter_count:  441 the loss: inf\n",
      "iter_count:  442 the loss: inf\n",
      "iter_count:  443 the loss: inf\n",
      "iter_count:  444 the loss: inf\n",
      "iter_count:  445 the loss: inf\n",
      "iter_count:  446 the loss: inf\n",
      "iter_count:  447 the loss: inf\n",
      "iter_count:  448 the loss: inf\n",
      "iter_count:  449 the loss: inf\n",
      "iter_count:  450 the loss: inf\n",
      "iter_count:  451 the loss: inf\n",
      "iter_count:  452 the loss: inf\n",
      "iter_count:  453 the loss: inf\n",
      "iter_count:  454 the loss: inf\n",
      "iter_count:  455 the loss: inf\n",
      "iter_count:  456 the loss: inf\n",
      "iter_count:  457 the loss: inf\n",
      "iter_count:  458 the loss: inf\n",
      "iter_count:  459 the loss: inf\n",
      "iter_count:  460 the loss: inf\n",
      "iter_count:  461 the loss: inf\n",
      "iter_count:  462 the loss: inf\n",
      "iter_count:  463 the loss: inf\n",
      "iter_count:  464 the loss: inf\n",
      "iter_count:  465 the loss: inf\n",
      "iter_count:  466 the loss: inf\n",
      "iter_count:  467 the loss: inf\n",
      "iter_count:  468 the loss: inf\n",
      "iter_count:  469 the loss: inf\n",
      "iter_count:  470 the loss: inf\n",
      "iter_count:  471 the loss: inf\n",
      "iter_count:  472 the loss: inf\n",
      "iter_count:  473 the loss: inf\n",
      "iter_count:  474 the loss: inf\n",
      "iter_count:  475 the loss: inf\n",
      "iter_count:  476 the loss: inf\n",
      "iter_count:  477 the loss: inf\n",
      "iter_count:  478 the loss: inf\n",
      "iter_count:  479 the loss: inf\n",
      "iter_count:  480 the loss: inf\n",
      "iter_count:  481 the loss: inf\n",
      "iter_count:  482 the loss: inf\n",
      "iter_count:  483 the loss: inf\n",
      "iter_count:  484 the loss: inf\n",
      "iter_count:  485 the loss: inf\n",
      "iter_count:  486 the loss: inf\n",
      "iter_count:  487 the loss: inf\n",
      "iter_count:  488 the loss: inf\n",
      "iter_count:  489 the loss: inf\n",
      "iter_count:  490 the loss: inf\n",
      "iter_count:  491 the loss: inf\n",
      "iter_count:  492 the loss: inf\n",
      "iter_count:  493 the loss: inf\n",
      "iter_count:  494 the loss: inf\n",
      "iter_count:  495 the loss: inf\n",
      "iter_count:  496 the loss: inf\n",
      "iter_count:  497 the loss: inf\n",
      "iter_count:  498 the loss: inf\n",
      "iter_count:  499 the loss: inf\n",
      "iter_count:  500 the loss: inf\n",
      "iter_count:  501 the loss: inf\n",
      "iter_count:  502 the loss: inf\n",
      "iter_count:  503 the loss: inf\n",
      "iter_count:  504 the loss: inf\n",
      "iter_count:  505 the loss: inf\n",
      "iter_count:  506 the loss: inf\n",
      "iter_count:  507 the loss: inf\n",
      "iter_count:  508 the loss: inf\n",
      "iter_count:  509 the loss: inf\n",
      "iter_count:  510 the loss: inf\n",
      "iter_count:  511 the loss: inf\n",
      "iter_count:  512 the loss: inf\n",
      "iter_count:  513 the loss: inf\n",
      "iter_count:  514 the loss: inf\n",
      "iter_count:  515 the loss: inf\n",
      "iter_count:  516 the loss: inf\n",
      "iter_count:  517 the loss: inf\n",
      "iter_count:  518 the loss: inf\n",
      "iter_count:  519 the loss: inf\n",
      "iter_count:  520 the loss: inf\n",
      "iter_count:  521 the loss: inf\n",
      "iter_count:  522 the loss: inf\n",
      "iter_count:  523 the loss: inf\n",
      "iter_count:  524 the loss: inf\n",
      "iter_count:  525 the loss: inf\n",
      "iter_count:  526 the loss: inf\n",
      "iter_count:  527 the loss: inf\n",
      "iter_count:  528 the loss: inf\n",
      "iter_count:  529 the loss: inf\n",
      "iter_count:  530 the loss: inf\n",
      "iter_count:  531 the loss: inf\n",
      "iter_count:  532 the loss: inf\n",
      "iter_count:  533 the loss: inf\n",
      "iter_count:  534 the loss: inf\n",
      "iter_count:  535 the loss: inf\n",
      "iter_count:  536 the loss: inf\n",
      "iter_count:  537 the loss: inf\n",
      "iter_count:  538 the loss: inf\n",
      "iter_count:  539 the loss: inf\n",
      "iter_count:  540 the loss: inf\n",
      "iter_count:  541 the loss: inf\n",
      "iter_count:  542 the loss: inf\n",
      "iter_count:  543 the loss: inf\n",
      "iter_count:  544 the loss: inf\n",
      "iter_count:  545 the loss: inf\n",
      "iter_count:  546 the loss: inf\n",
      "iter_count:  547 the loss: inf\n",
      "iter_count:  548 the loss: inf\n",
      "iter_count:  549 the loss: inf\n",
      "iter_count:  550 the loss: inf\n",
      "iter_count:  551 the loss: inf\n",
      "iter_count:  552 the loss: inf\n",
      "iter_count:  553 the loss: inf\n",
      "iter_count:  554 the loss: inf\n",
      "iter_count:  555 the loss: inf\n",
      "iter_count:  556 the loss: inf\n",
      "iter_count:  557 the loss: inf\n",
      "iter_count:  558 the loss: inf\n",
      "iter_count:  559 the loss: inf\n",
      "iter_count:  560 the loss: inf\n",
      "iter_count:  561 the loss: inf\n",
      "iter_count:  562 the loss: inf\n",
      "iter_count:  563 the loss: inf\n",
      "iter_count:  564 the loss: inf\n",
      "iter_count:  565 the loss: inf\n",
      "iter_count:  566 the loss: inf\n",
      "iter_count:  567 the loss: inf\n",
      "iter_count:  568 the loss: inf\n",
      "iter_count:  569 the loss: inf\n",
      "iter_count:  570 the loss: inf\n",
      "iter_count:  571 the loss: inf\n",
      "iter_count:  572 the loss: inf\n",
      "iter_count:  573 the loss: inf\n",
      "iter_count:  574 the loss: inf\n",
      "iter_count:  575 the loss: inf\n",
      "iter_count:  576 the loss: inf\n",
      "iter_count:  577 the loss: inf\n",
      "iter_count:  578 the loss: inf\n",
      "iter_count:  579 the loss: inf\n",
      "iter_count:  580 the loss: inf\n",
      "iter_count:  581 the loss: inf\n",
      "iter_count:  582 the loss: inf\n",
      "iter_count:  583 the loss: inf\n",
      "iter_count:  584 the loss: inf\n",
      "iter_count:  585 the loss: inf\n",
      "iter_count:  586 the loss: inf\n",
      "iter_count:  587 the loss: inf\n",
      "iter_count:  588 the loss: inf\n",
      "iter_count:  589 the loss: inf\n",
      "iter_count:  590 the loss: inf\n",
      "iter_count:  591 the loss: inf\n",
      "iter_count:  592 the loss: inf\n",
      "iter_count:  593 the loss: inf\n",
      "iter_count:  594 the loss: inf\n",
      "iter_count:  595 the loss: inf\n",
      "iter_count:  596 the loss: inf\n",
      "iter_count:  597 the loss: inf\n",
      "iter_count:  598 the loss: inf\n",
      "iter_count:  599 the loss: inf\n",
      "iter_count:  600 the loss: inf\n",
      "iter_count:  601 the loss: inf\n",
      "iter_count:  602 the loss: inf\n",
      "iter_count:  603 the loss: inf\n",
      "iter_count:  604 the loss: inf\n",
      "iter_count:  605 the loss: inf\n",
      "iter_count:  606 the loss: inf\n",
      "iter_count:  607 the loss: inf\n",
      "iter_count:  608 the loss: inf\n",
      "iter_count:  609 the loss: inf\n",
      "iter_count:  610 the loss: inf\n",
      "iter_count:  611 the loss: inf\n",
      "iter_count:  612 the loss: inf\n",
      "iter_count:  613 the loss: inf\n",
      "iter_count:  614 the loss: inf\n",
      "iter_count:  615 the loss: inf\n",
      "iter_count:  616 the loss: inf\n",
      "iter_count:  617 the loss: inf\n",
      "iter_count:  618 the loss: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  619 the loss: inf\n",
      "iter_count:  620 the loss: inf\n",
      "iter_count:  621 the loss: inf\n",
      "iter_count:  622 the loss: inf\n",
      "iter_count:  623 the loss: inf\n",
      "iter_count:  624 the loss: inf\n",
      "iter_count:  625 the loss: inf\n",
      "iter_count:  626 the loss: inf\n",
      "iter_count:  627 the loss: inf\n",
      "iter_count:  628 the loss: inf\n",
      "iter_count:  629 the loss: inf\n",
      "iter_count:  630 the loss: inf\n",
      "iter_count:  631 the loss: inf\n",
      "iter_count:  632 the loss: inf\n",
      "iter_count:  633 the loss: inf\n",
      "iter_count:  634 the loss: inf\n",
      "iter_count:  635 the loss: inf\n",
      "iter_count:  636 the loss: inf\n",
      "iter_count:  637 the loss: inf\n",
      "iter_count:  638 the loss: inf\n",
      "iter_count:  639 the loss: inf\n",
      "iter_count:  640 the loss: inf\n",
      "iter_count:  641 the loss: inf\n",
      "iter_count:  642 the loss: inf\n",
      "iter_count:  643 the loss: inf\n",
      "iter_count:  644 the loss: inf\n",
      "iter_count:  645 the loss: inf\n",
      "iter_count:  646 the loss: inf\n",
      "iter_count:  647 the loss: inf\n",
      "iter_count:  648 the loss: inf\n",
      "iter_count:  649 the loss: inf\n",
      "iter_count:  650 the loss: inf\n",
      "iter_count:  651 the loss: inf\n",
      "iter_count:  652 the loss: inf\n",
      "iter_count:  653 the loss: inf\n",
      "iter_count:  654 the loss: inf\n",
      "iter_count:  655 the loss: inf\n",
      "iter_count:  656 the loss: inf\n",
      "iter_count:  657 the loss: inf\n",
      "iter_count:  658 the loss: inf\n",
      "iter_count:  659 the loss: inf\n",
      "iter_count:  660 the loss: inf\n",
      "iter_count:  661 the loss: inf\n",
      "iter_count:  662 the loss: inf\n",
      "iter_count:  663 the loss: inf\n",
      "iter_count:  664 the loss: inf\n",
      "iter_count:  665 the loss: inf\n",
      "iter_count:  666 the loss: inf\n",
      "iter_count:  667 the loss: inf\n",
      "iter_count:  668 the loss: inf\n",
      "iter_count:  669 the loss: inf\n",
      "iter_count:  670 the loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-b3333ed59782>:33: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta[i] =theta[i] - step_size*(1/m)*(h - y[rand1])*samples[rand1,i]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    theta1,theta2,theta,loss_list = SGD(x, y)\n",
    "    print(theta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "问题：对于一个线性公式的问题，这个问题被建模成y=wx+b的问题，利用梯度下降算法，把最优w和b求出来\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(a=3, b=4, num=100):\n",
    "\t\"\"\" 构造数据 y = 4 + 3*x \"\"\"\n",
    "\tx1 = np.linspace(1, 10, num)\n",
    "\tx2 = np.linspace(1, 1, num)\n",
    "\tx = np.concatenate(([x1], [x2]), axis=0).T\n",
    "\ty = np.dot(x, [a, b])\n",
    "\treturn x, y\n",
    "\n",
    "def GD(x, y, step=0.1, loop=3000, eps=0.001):\n",
    "\tm, var = x.shape\n",
    "\ttheta = np.zeros(2)\n",
    "\titer_count = 0\n",
    "\titer_list = []\n",
    "\tloss_list = []\n",
    "\ttheta1 = []\n",
    "\ttheta2 = []\n",
    "\n",
    "\twhile True:\n",
    "\t\tloss = 0\n",
    "\t\t# 梯度计算\n",
    "\t\ttheta1.append(theta[0])\n",
    "\t\ttheta2.append(theta[1])\n",
    "\t\t# 样本维度下标\n",
    "\t\trand1 = np.random.randint(0, m, 1)\n",
    "\t\th = np.dot(theta, x[rand1].T)\n",
    "        theta[0] = theta[0] - step * (2 / m) * (h - y[rand1]) * x[rand1, i]\n",
    "\t\tfor j in range(m):\n",
    "\t\t\th = np.dot(theta.T, x[j])\n",
    "\t\t\t# 每组样本点损失的精度\n",
    "\t\t\tevery_loss = (1 / m) * np.power((h - y[j]), 2)\n",
    "\t\t\tloss = loss + every_loss\n",
    "\n",
    "\t\titer_list.append(iter_count)\n",
    "\t\tloss_list.append(loss)\n",
    "\t\titer_count += 1\n",
    "\t\t# 当损失精度达到要求 或 迭代次数到达上限退出循环\n",
    "\t\tif loss < eps or iter_count > loop:\n",
    "\t\t\tbreak\n",
    "\treturn theta1, theta2, theta, loss_list, iter_count, iter_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# 1、构造数据\n",
    "\tx, y = generate_data()\n",
    "\t# 2、梯度求解\n",
    "\ttheta1, theta2, theta, loss_list, iter_count, iter_list = GD(x, y, step = 1)\n",
    "\tprint('迭代求解结果为：{0}；\\n迭代次数为：{1}；\\n迭代结果误差为：{2}；' \\\n",
    "\t      .format(theta, iter_count, loss_list[-1]))\n",
    "\t# 3、可视化\n",
    "\tplt.plot(range(len(loss_list)), loss_list)\n",
    "\tplt.show()\n",
    "\t\"\"\"\n",
    "\tfig, ax = plt.subplots()\n",
    "\tax.scatter(x[:, 0], y, label = 'origin')\n",
    "\tax.plot(x[:, 0], np.dot(theta, x.T), 'r-', label = 'GD')\n",
    "\tplt.legend()\n",
    "\tplt.show()\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
