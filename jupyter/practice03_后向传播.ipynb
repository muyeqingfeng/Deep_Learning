{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\pygmt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    '''\n",
    "    ÂÖ®ËøûÊé•Â±ÇÔºö‰∏≠Èó¥Â±Ç\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim, activate='sigmoid'):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = np.random.normal(0,0.1,(input_dim, output_dim)) # WÈöèÊú∫ÂàùÂßãÂåñ: N(0,0.01)\n",
    "        self.b = np.zeros((output_dim,)) # bÂàùÂßãÂåñ: 0\n",
    "        self.act = activate\n",
    "\n",
    "    def activate(self, a, grad=False):\n",
    "        '''\n",
    "        a: (batch_size, output_dim)\n",
    "        return: (batch_size, output_dim)\n",
    "        '''\n",
    "        if self.act == 'sigmoid':\n",
    "            h = 1/(1+np.exp(-a))\n",
    "            if grad:\n",
    "                return h*(1-h)\n",
    "            return h\n",
    "        elif self.act == 'tanh':\n",
    "            h = np.tanh(a)\n",
    "            if grad:\n",
    "                return 1-h**2\n",
    "            return h\n",
    "        elif self.act == 'ReLU':\n",
    "            h = np.piecewise(a, [a > 0, a <= 0], [lambda x: x, lambda x: 0]) + 0  # +0‰∏∫‰∫ÜÊääarray(x)ËΩ¨Êàêx\n",
    "            if grad:\n",
    "                return np.piecewise(a, [a > 0, a <= 0], [lambda x: 1, lambda x: 0]) + 0 \n",
    "            return h\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        '''\n",
    "        input_data: (batch_size, input_dim)\n",
    "        return: (batch_size, output_dim)\n",
    "        '''\n",
    "        self.input_data = input_data\n",
    "        self.a = self.input_data.dot(self.W) + self.b\n",
    "        h = self.activate(self.a)\n",
    "        return h\n",
    "\n",
    "    def backward(self, input_grad, lr=0.01):\n",
    "        '''\n",
    "        BP in hidden layer\n",
    "        input_grad: (batch_size, output_dim)  ùúïL/ùúïh for this layer\n",
    "        return: (batch_size, input_dim)      ùúïL/ùúïh for previous layer\n",
    "        '''\n",
    "        batch_size = input_grad.shape[0]\n",
    "        a_grad = self.activate(self.a, grad=True) * input_grad # ùúïL/ùúïa (batch_size, output_dim)\n",
    "\n",
    "        b_grad = a_grad.mean(axis=0) # ùúïL/ùúïb (output_dim,)\n",
    "        self.b -= lr * b_grad\n",
    "\n",
    "        # ùúïL/ùúïW (input_dim, output_dim)\n",
    "        # (batch_size, 1, output_dim) * (batch_size, input_dim, 1) = (batch_size, input_dim, output_dim), then mean at axis=0\n",
    "        W_grad = (a_grad.reshape(batch_size,1,self.output_dim)*self.input_data.reshape(batch_size,self.input_dim,1)).mean(axis=0)\n",
    "        self.W -= lr * W_grad\n",
    "    \n",
    "        return a_grad.dot(self.W.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output_layer(Layer):\n",
    "    '''\n",
    "    ËæìÂá∫Â±ÇÔºöÁªßÊâøËá™‰∏≠Èó¥Â±Ç\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim, activate='softmax'):\n",
    "        super().__init__(input_dim, output_dim, activate='softmax')\n",
    "\n",
    "    def activate(self, a):\n",
    "        '''\n",
    "        activate in output layer\n",
    "        a: (batch_size, output_dim)\n",
    "        return: (batch_size, output_dim)\n",
    "            ‰ΩøÁî®softmaxÈªòËÆ§‰ΩøÁî®cross entropy loss\n",
    "            ‰ΩøÁî®linearÈªòËÆ§‰ΩøÁî®square loss\n",
    "            ËøôÊ†∑‰ΩøÂæóËæìÂá∫Â±Ç‰∏≠ÔºöùúïL/ùúïa = y_pred - y_train\n",
    "        '''\n",
    "        # softmaxÂíålinearÂØπÂ∫îÂàÜÁ±ª/ÂõûÂΩí‰ªªÂä°ÁöÑËæìÂá∫Â±Ç\n",
    "        if self.act == 'softmax':\n",
    "            h = np.exp(a)/(np.exp(a).sum(axis=1).reshape(a.shape[0],1)) \n",
    "            return h\n",
    "        elif self.act == 'linear':\n",
    "            return a\n",
    "    \n",
    "    def backward(self, input_grad, lr=0.01):\n",
    "        '''\n",
    "        BP in output layer\n",
    "        input_grad: (batch_size, output_dim)  ùúïL/ùúïa for output layer, usually y_pred-y\n",
    "        return: (batch_size, input_dim)       ùúïL/ùúïh for previous hidden layer\n",
    "        '''\n",
    "        batch_size = input_grad.shape[0]\n",
    "        a_grad = input_grad          # ùúïL/ùúïa (batch_size, output_dim)\n",
    "        b_grad = a_grad.mean(axis=0) # ùúïL/ùúïb (output_dim,)\n",
    "        self.b -= lr * b_grad\n",
    "        # ùúïL/ùúïW (input_dim, output_dim)\n",
    "        # (batch_size, 1, output_dim) * (batch_size, input_dim, 1) = (batch_size, input_dim, output_dim), then do average at axis=0\n",
    "        W_grad = (a_grad.reshape(batch_size,1,self.output_dim)*self.input_data.reshape(batch_size,self.input_dim,1)).mean(axis=0)\n",
    "        self.W -= lr * W_grad\n",
    "\n",
    "        return input_grad.dot(self.W.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 4) (150,) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# irisÊï∞ÊçÆÊµãËØï\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris['data']\n",
    "y = iris['target']\n",
    "train_x = (x-x.mean(axis=0))/(x.std(axis=0))\n",
    "train_y = to_categorical(y, num_classes=3)\n",
    "print(x.shape, train_x.shape, y.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂçïÂ±ÇsoftmaxÔºöÈÄªËæëÂõûÂΩíÂ§öÂàÜÁ±ªÊé®Âπø\n",
    "ly = Output_layer(input_dim=4, output_dim=3, activate='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc_set = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    y_pred = ly.forward(train_x)\n",
    "    input_grad = y_pred - train_y # ùúïL/ùúïa: softmax + cross_entropy\n",
    "    g1 = ly.backward(input_grad)\n",
    "\n",
    "    train_acc = (y_pred.argmax(axis=1)==y).sum()/y.size\n",
    "    train_acc_set.append(train_acc)\n",
    "\n",
    "plt.plot(train_acc_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "B = torch.tensor((1,2,3),dtype=torch.float32,requires_grad=True)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = B.pow(2).sum()\n",
    "y.backward()\n",
    "B.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmt",
   "language": "python",
   "name": "pygmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
