{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积网络构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # 提取特征层\n",
    "        self.features = nn.Sequential(\n",
    "            # 卷积层\n",
    "            # 输入图像通道为1，因为使用的是黑白图，单通道的\n",
    "            # 输出通道为32（代表使用32个卷积核），一个卷积和产生一个单通道的特征图\n",
    "            # 卷积核kernel_size的尺寸为 3*3， stride代表每次卷积核移动像素个数为1\n",
    "            # padding填充，为1代表图像长宽都多了两个像素\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            # 批量归一化，跟上一层的out_channels大小相等，\n",
    "            nn.BatchNorm2d(num_features=32), # 28*28*32 ---> 28*28*32\n",
    "\n",
    "            # 激活函数，inplace=true代表直接进行运算\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), #((28-3+2*1)/1)+1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 最大池化层\n",
    "            # kernel_size 为2*2的滑动窗口\n",
    "            # stride为2，表示每次滑动距离为2个像素\n",
    "            # 经过这一步，图像的大小变为1/4，即 28*28 ---> 7*7\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "        # 分类层\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Dropout层\n",
    "            # p = 0.5代表该层的每个权重有0.5的可能性为0\n",
    "            nn.Dropout(p=0.5),\n",
    "            # 这里是通道数 4* 图像大小 7*7，然后输入到512个神经元中\n",
    "            nn.Linear(64*7*7, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #　经过特征提取层\n",
    "        x = self.features(x)\n",
    "        # 输出结果必须 展开为 一维向量\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练前准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 引入库函数 \"\"\"\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim            # 优化模块，封装了求解模型的一些优化器如Adam,SGD\n",
    "from torchvision import datasets       # pytorch 视觉库提供了加载数据集的接口\n",
    "from torchvision import transforms     # pytorch 视觉库中提供了一些数据变换的接口\n",
    "import torch.nn.functional as F          # 提供了一些常用的函数，如softmax\n",
    "from torch.optim import lr_scheduler  # 学习率调整器，在训练过程中合理变动学习率\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\"\"\" 设置超参数 \"\"\"\n",
    "# 预设网络超参数 \n",
    "batch_size = 50 \n",
    "# 让torch判断是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\"\"\" 加载数据集 \"\"\"\n",
    "data_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "train_dataset = datasets.MNIST(root='.\\data', train=True, \n",
    "                               transform=data_transform, download=False)\n",
    "test_dataset = datasets.MNIST(root='.\\data', train=False,\n",
    "                             transform=data_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\"\"\" 训练前准备 \"\"\"\n",
    "# 初始化模型， 将网格操作移动到GPU或者CPU\n",
    "ConvModel = ConvNet().to(device)\n",
    "#　定义交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "#　定义模型优化器\n",
    "optimizer = optim.Adam(ConvModel.parameters(), lr=learning_rate)\n",
    "# 定义学习率调度器：输入包装的模型，定义学习率衰减周期step_size，gamma为衰减的乘法因子\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "# 如果学习率lr=0.05, 衰减周期step_size为30，耍贱乘法因子gamma=0.01\n",
    "# Assuming optimizer uses lr=0.05 for all groups\n",
    "# >>> # lr = 0.05     if epoch < 30\n",
    "# >>> # lr = 0.005    if 30 <= epoch < 60\n",
    "# >>> # lr = 0.0005   if 60 <= epoch < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, _model, _device, _train_loader, _optimizer, _lr_scheduler):\n",
    "    # 设置模型为训练模式\n",
    "    _model.train()  \n",
    "    # 设置学习率调度器开始准备更新\n",
    "    _lr_scheduler.step()\n",
    "    for epoch in range(num_epochs):\n",
    "        # 从迭代器抽取图片和标签\n",
    "        for i, (images, labels) in enumerate(_train_loader):\n",
    "            samples = images.to(_device)\n",
    "            labels = labels.to(_device)\n",
    "            # 此时样本是一批图片，在CNN的输入中，我们需要将其变为四维，\n",
    "            # reshape第一个-1 代表自动计算批量图片的数目n\n",
    "            # 最后reshape得到的结果就是n张图片，每一行图片都是单通道的28*28，得到的四维张量\n",
    "            output = _model(samples.reshape(-1, 1, 28, 28))\n",
    "            # 计算损失函数\n",
    "            loss = criterion(output, labels)\n",
    "            # 优化器内部参数梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 损失值后向传播\n",
    "            loss.backward()\n",
    "            # 更新模型参数\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"Epoch:{}/{}, step:{}, loss:{:.4f}\".format(epoch+1, \n",
    "                                            num_epochs, i+1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(_test_loader, _model, _device):\n",
    "    # 设置模型进入评估模式\n",
    "    _model.eval() \n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 如果不需要 backward更新梯度，那么就要禁用梯度计算，减少内存和计算资源\n",
    "        for data, target in _test_loader:\n",
    "            data, target = data.to(_device), target.to(_device)\n",
    "            output = ConvModel(data.reshape(-1, 1, 28, 28))\n",
    "            loss += criterion(output, target).item() # 添加损失值\n",
    "            pred = output.data.max(1, keepdim=True)[1] # 找到概率最大的下标，为输出值\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum() # .cpu()是将参数迁移到cpu\n",
    "            \n",
    "    loss /= len(_test_loader.dataset)\n",
    "    \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "            loss, correct, len(_test_loader.dataset),\n",
    "            100.* correct / len(_test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/1, step:100, loss:0.0455\n",
      "Epoch:1/1, step:200, loss:0.0519\n",
      "Epoch:1/1, step:300, loss:0.0519\n",
      "Epoch:1/1, step:400, loss:0.0773\n",
      "Epoch:1/1, step:500, loss:0.0092\n",
      "Epoch:1/1, step:600, loss:0.0796\n",
      "Epoch:1/1, step:700, loss:0.0026\n",
      "Epoch:1/1, step:800, loss:0.0143\n",
      "Epoch:1/1, step:900, loss:0.0509\n",
      "Epoch:1/1, step:1000, loss:0.0803\n",
      "Epoch:1/1, step:1100, loss:0.0048\n",
      "Epoch:1/1, step:1200, loss:0.1821\n",
      "\n",
      "Average loss: 0.0003, Accuracy: 9963/10000 (99.630%)\n",
      "\n",
      "\n",
      "Average loss: 0.0002, Accuracy: 59864/60000 (99.773%)\n",
      "\n",
      "Epoch:1/2, step:100, loss:0.0026\n",
      "Epoch:1/2, step:200, loss:0.0003\n",
      "Epoch:1/2, step:300, loss:0.0031\n",
      "Epoch:1/2, step:400, loss:0.0193\n",
      "Epoch:1/2, step:500, loss:0.0027\n",
      "Epoch:1/2, step:600, loss:0.0197\n",
      "Epoch:1/2, step:700, loss:0.0446\n",
      "Epoch:1/2, step:800, loss:0.0170\n",
      "Epoch:1/2, step:900, loss:0.0181\n",
      "Epoch:1/2, step:1000, loss:0.0020\n",
      "Epoch:1/2, step:1100, loss:0.0576\n",
      "Epoch:1/2, step:1200, loss:0.0013\n",
      "Epoch:2/2, step:100, loss:0.0069\n",
      "Epoch:2/2, step:200, loss:0.0003\n",
      "Epoch:2/2, step:300, loss:0.0008\n",
      "Epoch:2/2, step:400, loss:0.0683\n",
      "Epoch:2/2, step:500, loss:0.0003\n",
      "Epoch:2/2, step:600, loss:0.0034\n",
      "Epoch:2/2, step:700, loss:0.0152\n",
      "Epoch:2/2, step:800, loss:0.2248\n",
      "Epoch:2/2, step:900, loss:0.0284\n",
      "Epoch:2/2, step:1000, loss:0.0023\n",
      "Epoch:2/2, step:1100, loss:0.0104\n",
      "Epoch:2/2, step:1200, loss:0.0026\n",
      "\n",
      "Average loss: 0.0003, Accuracy: 9963/10000 (99.630%)\n",
      "\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 59896/60000 (99.827%)\n",
      "\n",
      "Epoch:1/3, step:100, loss:0.0009\n",
      "Epoch:1/3, step:200, loss:0.0007\n",
      "Epoch:1/3, step:300, loss:0.0025\n",
      "Epoch:1/3, step:400, loss:0.0053\n",
      "Epoch:1/3, step:500, loss:0.1513\n",
      "Epoch:1/3, step:600, loss:0.0008\n",
      "Epoch:1/3, step:700, loss:0.0004\n",
      "Epoch:1/3, step:800, loss:0.0094\n",
      "Epoch:1/3, step:900, loss:0.0163\n",
      "Epoch:1/3, step:1000, loss:0.0030\n",
      "Epoch:1/3, step:1100, loss:0.0014\n",
      "Epoch:1/3, step:1200, loss:0.0211\n",
      "Epoch:2/3, step:100, loss:0.0016\n",
      "Epoch:2/3, step:200, loss:0.0367\n",
      "Epoch:2/3, step:300, loss:0.0271\n",
      "Epoch:2/3, step:400, loss:0.0071\n",
      "Epoch:2/3, step:500, loss:0.0241\n",
      "Epoch:2/3, step:600, loss:0.0188\n",
      "Epoch:2/3, step:700, loss:0.0023\n",
      "Epoch:2/3, step:800, loss:0.0044\n",
      "Epoch:2/3, step:900, loss:0.0013\n",
      "Epoch:2/3, step:1000, loss:0.0331\n",
      "Epoch:2/3, step:1100, loss:0.0192\n",
      "Epoch:2/3, step:1200, loss:0.0011\n",
      "Epoch:3/3, step:100, loss:0.0992\n",
      "Epoch:3/3, step:200, loss:0.0016\n",
      "Epoch:3/3, step:300, loss:0.0087\n",
      "Epoch:3/3, step:400, loss:0.1309\n",
      "Epoch:3/3, step:500, loss:0.0213\n",
      "Epoch:3/3, step:600, loss:0.0581\n",
      "Epoch:3/3, step:700, loss:0.0171\n",
      "Epoch:3/3, step:800, loss:0.0012\n",
      "Epoch:3/3, step:900, loss:0.0098\n",
      "Epoch:3/3, step:1000, loss:0.0048\n",
      "Epoch:3/3, step:1100, loss:0.0006\n",
      "Epoch:3/3, step:1200, loss:0.0039\n",
      "\n",
      "Average loss: 0.0002, Accuracy: 9960/10000 (99.600%)\n",
      "\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 59918/60000 (99.863%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Epoch = 3\n",
    "for epoch in range(1, Epoch+1):\n",
    "    train(epoch, ConvModel, device, train_loader, optimizer, exp_lr_scheduler)\n",
    "    test(test_loader, ConvModel, device)\n",
    "    test(train_loader, ConvModel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmt",
   "language": "python",
   "name": "pygmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
